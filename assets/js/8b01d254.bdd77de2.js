(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[839],{3905:function(e,t,n){"use strict";n.d(t,{Zo:function(){return d},kt:function(){return c}});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var u=a.createContext({}),m=function(e){var t=a.useContext(u),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},d=function(e){var t=m(e.components);return a.createElement(u.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},s=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,i=e.originalType,u=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),s=m(n),c=r,f=s["".concat(u,".").concat(c)]||s[c]||p[c]||i;return n?a.createElement(f,o(o({ref:t},d),{},{components:n})):a.createElement(f,o({ref:t},d))}));function c(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=n.length,o=new Array(i);o[0]=s;var l={};for(var u in t)hasOwnProperty.call(t,u)&&(l[u]=t[u]);l.originalType=e,l.mdxType="string"==typeof e?e:r,o[1]=l;for(var m=2;m<i;m++)o[m]=n[m];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}s.displayName="MDXCreateElement"},9208:function(e,t,n){"use strict";n.r(t),n.d(t,{frontMatter:function(){return o},metadata:function(){return l},toc:function(){return u},default:function(){return d}});var a=n(2122),r=n(9756),i=(n(7294),n(3905)),o={title:"getWaveformPortion()",id:"get-waveform-portion"},l={unversionedId:"get-waveform-portion",id:"get-waveform-portion",isDocsHomePage:!1,title:"getWaveformPortion()",description:"Part of the @remotion/media-utils package of helper functions.",source:"@site/docs/get-waveform-portion.md",sourceDirName:".",slug:"/get-waveform-portion",permalink:"/docs/get-waveform-portion",editUrl:"https://github.com/JonnyBurger/remotion/edit/main/packages/docs/docs/get-waveform-portion.md",version:"current",frontMatter:{title:"getWaveformPortion()",id:"get-waveform-portion"},sidebar:"someSidebar",previous:{title:"getVideoMetadata()",permalink:"/docs/get-video-metadata"},next:{title:"useAudioData()",permalink:"/docs/use-audio-data"}},u=[{value:"Arguments",id:"arguments",children:[{value:"<code>options</code>",id:"options",children:[]}]},{value:"Return value",id:"return-value",children:[]},{value:"Example",id:"example",children:[]},{value:"Alternatives",id:"alternatives",children:[]}],m={toc:u};function d(e){var t=e.components,n=(0,r.Z)(e,["components"]);return(0,i.kt)("wrapper",(0,a.Z)({},m,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("p",null,(0,i.kt)("em",{parentName:"p"},"Part of the ",(0,i.kt)("inlineCode",{parentName:"em"},"@remotion/media-utils"))," package of helper functions."),(0,i.kt)("p",null,"Takes bulky waveform data (for example fetched by ",(0,i.kt)("a",{parentName:"p",href:"get-audio-data"},(0,i.kt)("inlineCode",{parentName:"a"},"getAudioData()")),") and returns a trimmed and simplified version of it, for simpler visualization. This function is suitable if you only need volume data, if you need more detailed data about each frequency range, use ",(0,i.kt)("a",{parentName:"p",href:"visualize-audio"},(0,i.kt)("inlineCode",{parentName:"a"},"visualizeAudio()")),"."),(0,i.kt)("h2",{id:"arguments"},"Arguments"),(0,i.kt)("h3",{id:"options"},(0,i.kt)("inlineCode",{parentName:"h3"},"options")),(0,i.kt)("p",null,"An object with the following arguments:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"audioData"),": ",(0,i.kt)("inlineCode",{parentName:"li"},"AudioData")," - information about the audio. Use ",(0,i.kt)("a",{parentName:"li",href:"get-audio-data"},(0,i.kt)("inlineCode",{parentName:"a"},"getAudioData()"))," to fetch it."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"startTimeInSeconds"),": ",(0,i.kt)("inlineCode",{parentName:"li"},"number")," - trim the waveform to exclude all data before ",(0,i.kt)("inlineCode",{parentName:"li"},"startTimeInSeconds"),"."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"durationInSeconds"),": ",(0,i.kt)("inlineCode",{parentName:"li"},"number")," - trim the waveform to exclude all data after ",(0,i.kt)("inlineCode",{parentName:"li"},"startTimeInSeconds + durationInSeconds"),"."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"numberOfSamples"),": ",(0,i.kt)("inlineCode",{parentName:"li"},"number")," - how big you want the result array to be. The function will compress the waveform to fit in ",(0,i.kt)("inlineCode",{parentName:"li"},"numberOfSamples")," data points.")),(0,i.kt)("h2",{id:"return-value"},"Return value"),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"Bar[]")," - An array of objects with the following properties:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"index"),": ",(0,i.kt)("inlineCode",{parentName:"li"},"number")," - the index of the datapoint, starting at 0. Useful for specifying as React ",(0,i.kt)("inlineCode",{parentName:"li"},"key")," attribute without getting a warning."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"amplitude"),": ",(0,i.kt)("inlineCode",{parentName:"li"},"number")," - a value describing the amplitude / volume / loudness of the audio.")),(0,i.kt)("h2",{id:"example"},"Example"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-tsx"},"import {getAudioData} from '@remotion/media-utils';\nimport music from './music.mp3';\n\nconst audioData = await getAudioData(music); /* {\n  channelWaveforms: [Float32Array(4410000), Float32Array(4410000)],\n  sampleRate: 44100,\n  durationInSeconds: 100.0000,\n  numberOfChannels: 2,\n  resultId: \"0.432878981\",\n  isRemote: false\n} */\n\nawait waveformPortion = getWaveformPortion({\n  audioData,\n  // Will select time range of 20-40 seconds\n  startTimeInSeconds: 20,\n  durationInSeconds: 20,\n  numberOfSamples: 10\n}) // [{index: 0, amplitude: 1.2203}, ... {index: 9, amplitude: 3.2211}]\n\nconsole.log(waveformPortion.length) // 10\n")),(0,i.kt)("h2",{id:"alternatives"},"Alternatives"),(0,i.kt)("p",null,"The ",(0,i.kt)("a",{parentName:"p",href:"visualize-audio"},(0,i.kt)("inlineCode",{parentName:"a"},"visualizeAudio()"))," function is more suitable for visualizing audio based on frequency properties of the audio (bass, mids, highs, etc)."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/docs/using-audio"},"Using audio")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/docs/audio"},(0,i.kt)("inlineCode",{parentName:"a"},"<Audio/>")))))}d.isMDXComponent=!0}}]);