(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4492],{3905:function(e,n,t){"use strict";t.r(n),t.d(n,{MDXContext:function(){return s},MDXProvider:function(){return c},mdx:function(){return h},useMDXComponents:function(){return m},withMDXComponents:function(){return l}});var i=t(2784);function o(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function a(){return(a=Object.assign||function(e){for(var n=1;n<arguments.length;n++){var t=arguments[n];for(var i in t)Object.prototype.hasOwnProperty.call(t,i)&&(e[i]=t[i])}return e}).apply(this,arguments)}function r(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);n&&(i=i.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,i)}return t}function u(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?r(Object(t),!0).forEach((function(n){o(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function d(e,n){if(null==e)return{};var t,i,o=function(e,n){if(null==e)return{};var t,i,o={},a=Object.keys(e);for(i=0;i<a.length;i++)t=a[i],n.indexOf(t)>=0||(o[t]=e[t]);return o}(e,n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(i=0;i<a.length;i++)t=a[i],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var s=i.createContext({}),l=function(e){return function(n){var t=m(n.components);return i.createElement(e,a({},n,{components:t}))}},m=function(e){var n=i.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):u(u({},n),e)),t},c=function(e){var n=m(e.components);return i.createElement(s.Provider,{value:n},e.children)},p={inlineCode:"code",wrapper:function(e){var n=e.children;return i.createElement(i.Fragment,{},n)}},f=i.forwardRef((function(e,n){var t=e.components,o=e.mdxType,a=e.originalType,r=e.parentName,s=d(e,["components","mdxType","originalType","parentName"]),l=m(t),c=o,f=l["".concat(r,".").concat(c)]||l[c]||p[c]||a;return t?i.createElement(f,u(u({ref:n},s),{},{components:t})):i.createElement(f,u({ref:n},s))}));function h(e,n){var t=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var a=t.length,r=new Array(a);r[0]=f;var u={};for(var d in n)hasOwnProperty.call(n,d)&&(u[d]=n[d]);u.originalType=e,u.mdxType="string"==typeof e?e:o,r[1]=u;for(var s=2;s<a;s++)r[s]=t[s];return i.createElement.apply(null,r)}return i.createElement.apply(null,t)}f.displayName="MDXCreateElement"},37886:function(e,n,t){"use strict";t.r(n),t.d(n,{frontMatter:function(){return r},metadata:function(){return u},toc:function(){return d},default:function(){return l}});var i=t(22122),o=t(19756),a=(t(2784),t(3905)),r={title:"Audio visualization",id:"audio-visualization"},u={unversionedId:"audio-visualization",id:"audio-visualization",isDocsHomePage:!1,title:"Audio visualization",description:"Using the audio visualization APIs in Remotion 2.0, you can create animations based on the frequency of the audio. This is often used to make graphics react to the volume or sound spectrum of the music.",source:"@site/docs/audio-visualization.md",sourceDirName:".",slug:"/audio-visualization",permalink:"/docs/audio-visualization",editUrl:"https://github.com/JonnyBurger/remotion/edit/main/packages/docs/docs/audio-visualization.md",version:"current",frontMatter:{title:"Audio visualization",id:"audio-visualization"},sidebar:"someSidebar",previous:{title:"Using randomness",permalink:"/docs/using-randomness"},next:{title:"<Img> and <IFrame> tags",permalink:"/docs/use-img-and-iframe"}},d=[{value:"Import audio",id:"import-audio",children:[]},{value:"Render audio visualization",id:"render-audio-visualization",children:[]},{value:"See also",id:"see-also",children:[]}],s={toc:d};function l(e){var n=e.components,t=(0,o.default)(e,["components"]);return(0,a.mdx)("wrapper",(0,i.default)({},s,t,{components:n,mdxType:"MDXLayout"}),(0,a.mdx)("p",null,"Using the audio visualization APIs in Remotion 2.0, you can create animations based on the frequency of the audio. This is often used to make graphics react to the volume or sound spectrum of the music."),(0,a.mdx)("h2",{id:"import-audio"},"Import audio"),(0,a.mdx)("p",null,"You can import an audio file using an ",(0,a.mdx)("inlineCode",{parentName:"p"},"import")," statement:"),(0,a.mdx)("pre",null,(0,a.mdx)("code",{parentName:"pre",className:"language-tsx"},"import audio from './audio.mp3'\n")),(0,a.mdx)("p",null,(0,a.mdx)("inlineCode",{parentName:"p"},"audio")," will resolve to a string pointing to an audio file. You may also skip importing and use an ",(0,a.mdx)("inlineCode",{parentName:"p"},"https://")," URL to load audio from a remote location, if the audio is allowed to be loaded by the domains CORS policy."),(0,a.mdx)("h2",{id:"render-audio-visualization"},"Render audio visualization"),(0,a.mdx)("p",null,"The ",(0,a.mdx)("inlineCode",{parentName:"p"},"@remotion/media-utils")," package provides helper functions for reading and processing audio. Using the ",(0,a.mdx)("a",{parentName:"p",href:"/docs/get-audio-data"},(0,a.mdx)("inlineCode",{parentName:"a"},"getAudioData()"))," API you can read audio, and using the ",(0,a.mdx)("a",{parentName:"p",href:"/docs/use-audio-data"},(0,a.mdx)("inlineCode",{parentName:"a"},"useAudioData()"))," helper hook you can load this audio data directly into your component."),(0,a.mdx)("p",null,"Using the ",(0,a.mdx)("a",{parentName:"p",href:"/docs/visualize-audio"},(0,a.mdx)("inlineCode",{parentName:"a"},"visualizeAudio()"))," API, you can get an audio spectrum for the current frame, with the ",(0,a.mdx)("inlineCode",{parentName:"p"},"numberOfSamples")," parameter being an option to control the amount of detail you need."),(0,a.mdx)("p",null,"Refer to the documentation of the above mentioned functions to learn more."),(0,a.mdx)("pre",null,(0,a.mdx)("code",{parentName:"pre",className:"language-tsx"},"import {useCurrentFrame, useVideoConfig, Audio} from 'remotion';\nimport {useAudioData, visualizeAudio} from '@remotion/media-utils';\nimport music from './music.mp3';\n\nexport const MyComponent: React.FC = () => {\n  const frame = useCurrentFrame();\n  const {width, height, fps} = useVideoConfig();\n  const audioData = useAudioData(music);\n\n  if (!audioData) {\n    return null;\n  }\n\n  const visualization = visualizeAudio({\n    fps,\n    frame,\n    audioData,\n    numberOfSamples: 16,\n  }); // [0.22, 0.1, 0.01, 0.01, 0.01, 0.02, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n\n  // Render a bar chart for each frequency, the higher the amplitude,\n  // the longer the bar\n  return (\n    <div>\n      <Audio src={music}/>\n      {visualization.map(v => {\n        return (\n          <div style={{width: 1000 * v, height: 15, backgroundColor: 'blue'}} />\n        );\n      })}\n    </div>\n  )\n}\n")),(0,a.mdx)("h2",{id:"see-also"},"See also"),(0,a.mdx)("ul",null,(0,a.mdx)("li",{parentName:"ul"},(0,a.mdx)("a",{parentName:"li",href:"/docs/using-audio"},"Using audio")),(0,a.mdx)("li",{parentName:"ul"},(0,a.mdx)("a",{parentName:"li",href:"/docs/use-audio-data"},(0,a.mdx)("inlineCode",{parentName:"a"},"useAudioData()"))),(0,a.mdx)("li",{parentName:"ul"},(0,a.mdx)("a",{parentName:"li",href:"/docs/visualize-audio"},(0,a.mdx)("inlineCode",{parentName:"a"},"visualizeAudio()")))))}l.isMDXComponent=!0}}]);